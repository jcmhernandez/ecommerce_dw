{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_fact_warehouse_summary() missing 1 required positional argument: 'dim_warehouse_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 218\u001b[0m\n\u001b[0;32m    216\u001b[0m sku_data \u001b[38;5;241m=\u001b[39m generate_fact_sku_performance_summary(\u001b[38;5;241m1000\u001b[39m, date_keys, sku_ids)\n\u001b[0;32m    217\u001b[0m seller_data \u001b[38;5;241m=\u001b[39m generate_fact_seller_performance_summary(\u001b[38;5;241m1000\u001b[39m, date_keys, shop_ids)\n\u001b[1;32m--> 218\u001b[0m warehouse_data_fact \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_fact_warehouse_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwh_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m staff_data \u001b[38;5;241m=\u001b[39m generate_fact_staff_prod_summary(\u001b[38;5;241m1000\u001b[39m, date_keys, wh_keys)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# Save each DataFrame to a CSV file\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_fact_warehouse_summary() missing 1 required positional argument: 'dim_warehouse_df'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Function to generate dim_date data for November to December 2024\n",
    "def generate_dim_date():\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    end_date = datetime(2024, 12, 31)\n",
    "    date_list = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    data = []\n",
    "    for date in date_list:\n",
    "        record = {\n",
    "            'date_key': date.strftime('%Y-%m-%d'),\n",
    "            'date': date,\n",
    "            'quarter': 4,\n",
    "            'year': date.year,\n",
    "            'month': date.month,\n",
    "            'day': date.day,\n",
    "            'day_of_week': date.weekday(),\n",
    "            'day_type': 'Weekend' if date.weekday() >= 5 else 'Weekday',\n",
    "            'is_holiday': random.choice([True, False]),\n",
    "            'is_campaign_day': random.choice([True, False]),\n",
    "            'is_salary_day': random.choice([True, False]),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to generate dim_item data\n",
    "def generate_dim_item(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'sku_key': fake.uuid4(),\n",
    "            'sku_id': fake.uuid4(),\n",
    "            'shop_id': fake.uuid4(),\n",
    "            'listing_id': fake.uuid4(),\n",
    "            'listing_name': fake.word(),\n",
    "            'listing_description': fake.sentence(),\n",
    "            'category_lvl_1': fake.word(),\n",
    "            'category_lvl_2': fake.word(),\n",
    "            'model_id': fake.uuid4(),\n",
    "            'item_id': fake.uuid4(),\n",
    "            'model_name': fake.word(),\n",
    "            'item_description': fake.sentence(),\n",
    "            'weight': random.uniform(0.1, 10.0),\n",
    "            'length': random.uniform(0.1, 100.0),\n",
    "            'width': random.uniform(0.1, 100.0),\n",
    "            'height': random.uniform(0.1, 100.0),\n",
    "            'item_price': random.uniform(1.0, 1000.0),\n",
    "            'is_active': random.choice([True, False]),\n",
    "            'create_time': fake.date_time_this_decade(),\n",
    "            'banned_time': fake.date_time_this_decade(),\n",
    "            'last_modified_time': fake.date_time_this_decade(),\n",
    "            'is_wh': random.choice([True, False]),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to generate dim_warehouse data\n",
    "def generate_dim_warehouse(num_records):\n",
    "    warehouse_types = ['WHA', 'WHB', 'WHC']  # Restrict warehouse types\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'wh_key': fake.uuid4(),\n",
    "            'wh_id': fake.uuid4(),\n",
    "            'wh_name': fake.company(),\n",
    "            'wh_type': random.choice(warehouse_types),  # Restricted to WHA, WHB, WHC\n",
    "            'wh_region': fake.state(),\n",
    "            'wh_city': fake.city(),\n",
    "            'wh_brgy': fake.street_name(),\n",
    "            'wh_postal_code': fake.postcode(),\n",
    "            'total_land_area': random.uniform(1000.0, 10000.0),\n",
    "            'operating_hours': random.randint(8, 24),\n",
    "            'is_active': random.choice([True, False]),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generate dimension tables\n",
    "date_data = generate_dim_date()\n",
    "item_data = generate_dim_item(100)\n",
    "warehouse_data = generate_dim_warehouse(100)\n",
    "\n",
    "# Function to generate fact_platform_performance_summary data\n",
    "def generate_fact_platform_performance_summary(num_records, date_keys):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'date_key': random.choice(date_keys),\n",
    "            'l1d_ado': random.uniform(0, 100),\n",
    "            'l7d_ado': random.uniform(0, 100),\n",
    "            'l30d_ado': random.uniform(0, 100),\n",
    "            'l1d_adgmv': random.uniform(0, 100),\n",
    "            'l7d_adgmv': random.uniform(0, 100),\n",
    "            'l30d_adgmv': random.uniform(0, 100),\n",
    "            'l1d_avg_active_buyers': random.uniform(0, 100),\n",
    "            'l7d_avg_active_buyers': random.uniform(0, 100),\n",
    "            'l30d_avg_active_buyers': random.uniform(0, 100),\n",
    "            'l1d_avg_active_shops': random.uniform(0, 100),\n",
    "            'l7d_avg_active_shops': random.uniform(0, 100),\n",
    "            'l30d_avg_active_shops': random.uniform(0, 100),\n",
    "            'l1d_otd_time': random.uniform(0, 100),\n",
    "            'l7d_otd_time': random.uniform(0, 100),\n",
    "            'l30d_otd_time': random.uniform(0, 100),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to generate fact_sku_performance_summary data\n",
    "def generate_fact_sku_performance_summary(num_records, date_keys, sku_ids):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'date_key': random.choice(date_keys),\n",
    "            'sku_id': random.choice(sku_ids),\n",
    "            'l1d_ado': random.uniform(0, 100),\n",
    "            'l7d_ado': random.uniform(0, 100),\n",
    "            'l30d_ado': random.uniform(0, 100),\n",
    "            'l90d_ado': random.uniform(0, 100),\n",
    "            'l1d_adgmv': random.uniform(0, 100),\n",
    "            'l7d_adgmv': random.uniform(0, 100),\n",
    "            'l30d_adgmv': random.uniform(0, 100),\n",
    "            'l90d_adgmv': random.uniform(0, 100),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to generate fact_seller_performance_summary data\n",
    "def generate_fact_seller_performance_summary(num_records, date_keys, shop_ids):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'date_key': random.choice(date_keys),\n",
    "            'shop_id': random.choice(shop_ids),\n",
    "            'l1d_ado': random.uniform(0, 100),\n",
    "            'l7d_ado': random.uniform(0, 100),\n",
    "            'l30d_ado': random.uniform(0, 100),\n",
    "            'l90d_ado': random.uniform(0, 100),\n",
    "            'l1d_adgmv': random.uniform(0, 100),\n",
    "            'l7d_adgmv': random.uniform(0, 100),\n",
    "            'l30d_adgmv': random.uniform(0, 100),\n",
    "            'l90d_adgmv': random.uniform(0, 100),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to generate fact_warehouse_summary data\n",
    "def generate_fact_warehouse_summary(num_records, date_keys, dim_warehouse_df):\n",
    "    # Filter for WHA, WHB, WHC types\n",
    "    valid_wh_keys = dim_warehouse_df[dim_warehouse_df['wh_type'].isin(['WHA', 'WHB', 'WHC'])]['wh_key'].tolist()\n",
    "    \n",
    "    data = []\n",
    "    existing_combinations = set()\n",
    "    while len(data) < num_records:\n",
    "        date_key = random.choice(date_keys)\n",
    "        wh_key = random.choice(valid_wh_keys)  # Choose only from WHA, WHB, WHC\n",
    "        \n",
    "        combination = (wh_key, date_key)\n",
    "        if combination not in existing_combinations:\n",
    "            record = {\n",
    "                'date_key': date_key,\n",
    "                'wh_key': wh_key,\n",
    "                'total_items': random.randint(0, 1000),\n",
    "                'total_manhours': random.uniform(0, 1000),\n",
    "                'total_active_manhours': random.uniform(0, 1000),\n",
    "                'l1d_ado': random.uniform(0, 100),\n",
    "                'l7d_ado': random.uniform(0, 100),\n",
    "                'l30d_ado': random.uniform(0, 100),\n",
    "                'l1d_adi': random.uniform(0, 100),\n",
    "                'l7d_adi': random.uniform(0, 100),\n",
    "                'l30d_adi': random.uniform(0, 100),\n",
    "                'l1d_prod_rate': random.uniform(0, 100),\n",
    "                'l7d_prod_rate': random.uniform(0, 100),\n",
    "                'l30d_prod_rate': random.uniform(0, 100),\n",
    "                'l1d_idle_rate': random.uniform(0, 100),\n",
    "                'l7d_idle_rate': random.uniform(0, 100),\n",
    "                'l30d_idle_rate': random.uniform(0, 100),\n",
    "            }\n",
    "            data.append(record)\n",
    "            existing_combinations.add(combination)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Function to generate fact_staff_prod_summary data\n",
    "def generate_fact_staff_prod_summary(num_records, date_keys, wh_keys):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'staff_key': fake.uuid4(),\n",
    "            'date_key': random.choice(date_keys),\n",
    "            'wh_key': random.choice(wh_keys),\n",
    "            'total_items': random.randint(0, 1000),\n",
    "            'total_manhours': random.uniform(0, 1000),\n",
    "            'total_active_manhours': random.uniform(0, 1000),\n",
    "            'prod_rate': random.uniform(0, 100),\n",
    "            'idle_rate': random.uniform(0, 100),\n",
    "        }\n",
    "        data.append(record)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Retrieve keys for fact table generation\n",
    "date_keys = date_data['date_key'].tolist()\n",
    "sku_ids = item_data['sku_id'].tolist()\n",
    "shop_ids = item_data['shop_id'].tolist()\n",
    "wh_keys = warehouse_data['wh_key'].tolist()\n",
    "\n",
    "# Generate fact tables\n",
    "platform_data = generate_fact_platform_performance_summary(1000, date_keys)\n",
    "sku_data = generate_fact_sku_performance_summary(1000, date_keys, sku_ids)\n",
    "seller_data = generate_fact_seller_performance_summary(1000, date_keys, shop_ids)\n",
    "warehouse_data_fact = generate_fact_warehouse_summary(1000, date_keys, warehouse_data)\n",
    "staff_data = generate_fact_staff_prod_summary(1000, date_keys, wh_keys)\n",
    "\n",
    "# Save each DataFrame to a CSV file\n",
    "date_data.to_csv('dim_date.csv', index=False)\n",
    "item_data.to_csv('dim_item.csv', index=False)\n",
    "warehouse_data.to_csv('dim_warehouse.csv', index=False)\n",
    "platform_data.to_csv('fact_platform_performance_summary.csv', index=False)\n",
    "sku_data.to_csv('fact_sku_performance_summary.csv', index=False)\n",
    "seller_data.to_csv('fact_seller_performance_summary.csv', index=False)\n",
    "warehouse_data_fact.to_csv('fact_warehouse_summary.csv', index=False)\n",
    "staff_data.to_csv('fact_staff_prod_summary.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
